{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import torchvision\n",
    "from torchvision.transforms import ToTensor, Normalize, Compose"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "source": [
    "from scripts.architecture import MLP\n",
    "from scripts.train import *\n",
    "from scripts.plot_utils import plot_loss_accuracy, plotValAccuracy"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "source": [
    "print(torch.__version__)\n",
    "print(np.__version__)"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "1.9.0\n",
      "1.20.3\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Create Parity Data Iterator"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "source": [
    "transforms = Compose([\n",
    "    ToTensor(),\n",
    "    Normalize((0.1307,), (0.3081,))\n",
    "])"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "source": [
    "# doesn't perform and transformation until we call the loader\n",
    "trainset = torchvision.datasets.MNIST(root='data', train=True, download=True, transform=transforms)\n",
    "testset = torchvision.datasets.MNIST(root='data', train=False, download=True, transform=transforms)"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "/home/john/anaconda3/lib/python3.8/site-packages/torchvision/datasets/mnist.py:498: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1623448234945/work/torch/csrc/utils/tensor_numpy.cpp:180.)\n",
      "  return torch.from_numpy(parsed.astype(m[2], copy=False)).view(*s)\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "source": [
    "learn_rate = 0.05\n",
    "num_epochs = 20\n",
    "batch_size = 128\n",
    "loss_fn = torch.nn.BCEWithLogitsLoss()"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "### For k = 1"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "k=1\n",
    "model = MLP(k, \"ReLU\")\n",
    "optimizer = torch.optim.Adadelta(model.parameters(), lr=learn_rate, weight_decay = 0.001)\n",
    "\n",
    "trainLostList, trainAccList, valLossList, valAccList  = train_model(model, k, trainset, testset, loss_fn, optimizer, num_epochs, batch_size, validate_model = True,\n",
    "                                                                     performance=accuracy_manual, device=\"cuda:0\", lr_scheduler=None)\n"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "plot_loss_accuracy(trainLostList,valLossList,trainAccList,valAccList,num_epochs)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "source": [
    "k=1\n",
    "model2 = MLP(k, \"ReLU\")\n",
    "optimizer = torch.optim.SGD(model2.parameters(), lr=learn_rate)\n",
    "\n",
    "trainLostList, trainAccList, valLossList, valAccList  = train_model(model2, k, trainset, testset, loss_fn, optimizer, num_epochs, batch_size, validate_model = True,\n",
    "                                                                     performance=accuracy_manual, device=\"cpu\",lr = learn_rate, lr_scheduler=None, updateWManually=False)\n"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Training on cpu\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "/home/john/anaconda3/lib/python3.8/site-packages/torch/autograd/__init__.py:147: UserWarning: CUDA initialization: CUDA unknown error - this may be due to an incorrectly set up environment, e.g. changing env variable CUDA_VISIBLE_DEVICES after program start. Setting the available devices to be zero. (Triggered internally at  /opt/conda/conda-bld/pytorch_1623448234945/work/c10/cuda/CUDAFunctions.cpp:115.)\n",
      "  Variable._execution_engine.run_backward(\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Epoch 1 completed. Loss - total: 11845.9674 - average: 0.1974; Performance: 0.9208\n",
      "TESTING - loss 1181.6230304539204 - performance 0.9571\n",
      "Epoch 2 completed. Loss - total: 5777.0455 - average: 0.0963; Performance: 0.9655\n",
      "TESTING - loss 835.5479165911674 - performance 0.9702\n",
      "Epoch 3 completed. Loss - total: 4419.5596 - average: 0.0737; Performance: 0.9742\n",
      "TESTING - loss 693.2081878185272 - performance 0.9767\n",
      "Epoch 4 completed. Loss - total: 3673.7891 - average: 0.0612; Performance: 0.9784\n",
      "TESTING - loss 610.065970569849 - performance 0.9798\n",
      "Epoch 5 completed. Loss - total: 3168.9639 - average: 0.0528; Performance: 0.9815\n",
      "TESTING - loss 555.7761751115322 - performance 0.9819\n",
      "Epoch 6 completed. Loss - total: 2789.5517 - average: 0.0465; Performance: 0.9837\n",
      "TESTING - loss 516.1964055150747 - performance 0.9827\n",
      "Epoch 7 completed. Loss - total: 2488.0638 - average: 0.0415; Performance: 0.9856\n",
      "TESTING - loss 486.1013423651457 - performance 0.9832\n",
      "Epoch 8 completed. Loss - total: 2234.5499 - average: 0.0372; Performance: 0.9871\n",
      "TESTING - loss 462.8809941932559 - performance 0.9839\n",
      "Epoch 9 completed. Loss - total: 2015.9577 - average: 0.0336; Performance: 0.9886\n",
      "TESTING - loss 445.45364286750555 - performance 0.9849\n",
      "Epoch 10 completed. Loss - total: 1826.9635 - average: 0.0304; Performance: 0.9900\n",
      "TESTING - loss 432.4579006060958 - performance 0.9862\n",
      "Epoch 11 completed. Loss - total: 1659.3521 - average: 0.0277; Performance: 0.9912\n",
      "TESTING - loss 421.14291712641716 - performance 0.9865\n",
      "Epoch 12 completed. Loss - total: 1509.1134 - average: 0.0252; Performance: 0.9924\n",
      "TESTING - loss 412.67351619899273 - performance 0.9864\n",
      "Epoch 13 completed. Loss - total: 1375.6148 - average: 0.0229; Performance: 0.9932\n",
      "TESTING - loss 405.41571844369173 - performance 0.9864\n",
      "Epoch 14 completed. Loss - total: 1255.8681 - average: 0.0209; Performance: 0.9940\n",
      "TESTING - loss 402.0797871053219 - performance 0.9864\n",
      "Epoch 15 completed. Loss - total: 1148.7216 - average: 0.0191; Performance: 0.9949\n",
      "TESTING - loss 397.4071480333805 - performance 0.9866\n",
      "Epoch 16 completed. Loss - total: 1051.9592 - average: 0.0175; Performance: 0.9954\n",
      "TESTING - loss 395.10910492390394 - performance 0.9869\n",
      "Epoch 17 completed. Loss - total: 964.5457 - average: 0.0161; Performance: 0.9959\n",
      "TESTING - loss 393.2023299857974 - performance 0.9868\n",
      "Epoch 18 completed. Loss - total: 886.0138 - average: 0.0148; Performance: 0.9963\n",
      "TESTING - loss 392.55897887051105 - performance 0.9872\n",
      "Epoch 19 completed. Loss - total: 815.1236 - average: 0.0136; Performance: 0.9968\n",
      "TESTING - loss 390.8828003332019 - performance 0.9869\n",
      "Epoch 20 completed. Loss - total: 750.7324 - average: 0.0125; Performance: 0.9972\n",
      "TESTING - loss 387.6189645379782 - performance 0.9867\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "source": [
    "with open('SGD_k1_pytorch.txt', 'w') as f:\n",
    "    for item in valAccList:\n",
    "        f.write(\"%s\\n\" % item)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "plot_loss_accuracy(trainLostList,valLossList,trainAccList,valAccList,num_epochs)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "### For k = 3"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "k = 3\n",
    "\n",
    "model3 = MLP(k,\"ReLU\")\n",
    "optimizer = torch.optim.Adadelta(model3.parameters(), lr=learn_rate, weight_decay = 0.001)\n",
    "\n",
    "trainLostList3, trainAccList3, valLossList3, valAccList3  = train_model(model3, k, trainset, testset, loss_fn, optimizer, num_epochs, batch_size, validate_model = True,\n",
    "                                                                     performance=accuracy_manual, device=\"cuda:0\", lr_scheduler=None)\n"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "plot_loss_accuracy(trainLostList3,valLossList3,trainAccList3,valAccList3,num_epochs)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "source": [
    "k = 3\n",
    "model4 = MLP(k, \"ReLU\")\n",
    "optimizer = torch.optim.SGD(model4.parameters(), lr=learn_rate, weight_decay = 0.001)\n",
    "\n",
    "trainLostList4, trainAccList4, valLossList4, valAccList4  = train_model(model4, k, trainset, testset, loss_fn, optimizer, num_epochs, batch_size, validate_model = True,\n",
    "                                                                     performance=accuracy_manual, device=\"cpu\", lr_scheduler=None)\n"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Training on cpu\n",
      "Epoch 1 completed. Loss - total: 41782.3516 - average: 0.6964; Performance: 0.4999\n",
      "TESTING - loss 6949.679255485535 - performance 0.5028\n",
      "Epoch 2 completed. Loss - total: 41615.4926 - average: 0.6936; Performance: 0.4986\n",
      "TESTING - loss 6917.064130306244 - performance 0.4944\n",
      "Epoch 3 completed. Loss - total: 41082.2017 - average: 0.6847; Performance: 0.5073\n",
      "TESTING - loss 6713.841676712036 - performance 0.5459\n",
      "Epoch 4 completed. Loss - total: 39043.5335 - average: 0.6507; Performance: 0.5532\n",
      "TESTING - loss 6315.076053142548 - performance 0.5686\n",
      "Epoch 5 completed. Loss - total: 36368.0561 - average: 0.6061; Performance: 0.6206\n",
      "TESTING - loss 5871.085584163666 - performance 0.6534\n",
      "Epoch 6 completed. Loss - total: 34835.6712 - average: 0.5806; Performance: 0.6539\n",
      "TESTING - loss 5625.438928604126 - performance 0.6616\n",
      "Epoch 7 completed. Loss - total: 33804.9682 - average: 0.5634; Performance: 0.6679\n",
      "TESTING - loss 5547.36864566803 - performance 0.6939\n",
      "Epoch 8 completed. Loss - total: 33330.1837 - average: 0.5555; Performance: 0.6734\n",
      "TESTING - loss 5415.4908657073975 - performance 0.6922\n",
      "Epoch 9 completed. Loss - total: 32927.3408 - average: 0.5488; Performance: 0.6807\n",
      "TESTING - loss 5389.963775873184 - performance 0.6782\n",
      "Epoch 10 completed. Loss - total: 32487.8815 - average: 0.5415; Performance: 0.6863\n",
      "TESTING - loss 5348.487079143524 - performance 0.7047\n",
      "Epoch 11 completed. Loss - total: 32236.9211 - average: 0.5373; Performance: 0.6935\n",
      "TESTING - loss 5416.005969047546 - performance 0.7097\n",
      "Epoch 12 completed. Loss - total: 31814.2075 - average: 0.5302; Performance: 0.6976\n",
      "TESTING - loss 5289.183735847473 - performance 0.7040\n",
      "Epoch 13 completed. Loss - total: 31586.6078 - average: 0.5264; Performance: 0.7010\n",
      "TESTING - loss 5397.8347182273865 - performance 0.7101\n",
      "Epoch 14 completed. Loss - total: 31263.1224 - average: 0.5211; Performance: 0.7066\n",
      "TESTING - loss 5182.117581367493 - performance 0.6914\n",
      "Epoch 15 completed. Loss - total: 31013.9019 - average: 0.5169; Performance: 0.7077\n",
      "TESTING - loss 5237.348645925522 - performance 0.6949\n",
      "Epoch 16 completed. Loss - total: 30844.7522 - average: 0.5141; Performance: 0.7125\n",
      "TESTING - loss 5069.658994674683 - performance 0.7215\n",
      "Epoch 17 completed. Loss - total: 30477.5441 - average: 0.5080; Performance: 0.7149\n",
      "TESTING - loss 5078.470140695572 - performance 0.7136\n",
      "Epoch 18 completed. Loss - total: 30405.9605 - average: 0.5068; Performance: 0.7175\n",
      "TESTING - loss 5028.46947312355 - performance 0.7053\n",
      "Epoch 19 completed. Loss - total: 30030.2716 - average: 0.5005; Performance: 0.7206\n",
      "TESTING - loss 5133.117079734802 - performance 0.7072\n",
      "Epoch 20 completed. Loss - total: 30053.2299 - average: 0.5009; Performance: 0.7235\n",
      "TESTING - loss 4986.219584941864 - performance 0.7117\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "source": [
    "with open('SGD_k3_pytorch.txt', 'w') as f:\n",
    "    for item in valAccList4:\n",
    "        f.write(\"%s\\n\" % item)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "plot_loss_accuracy(trainLostList4,valLossList4,trainAccList4,valAccList4,num_epochs)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "# Add Lazy methods\n",
    "learn_rate = 0.05\n",
    "K = 3\n",
    "num_epochs = 20\n",
    "\n",
    "fig = plt.figure()\n",
    "for activation in [\"ReLU\", \"NTK\", \"Gaussian features\", \"ReLU features\", \"linear features\", \"SGD\"]:\n",
    "    model = MLP(K, activation)\n",
    "\n",
    "    if \"features\" in activation:\n",
    "        # deactivate the first layer\n",
    "        optimizer = torch.optim.Adadelta(model.layer2.parameters(), lr = learn_rate, weight_decay=0.001)\n",
    "    elif \"NTK\" in activation:\n",
    "        paramsToUpdate = list(model.layer1.parameters()) + list(model.layer2.parameters())\n",
    "        optimizer = torch.optim.Adadelta(paramsToUpdate, lr = learn_rate, weight_decay=0.001)\n",
    "    elif \"SGD\" in activation:\n",
    "        optimizer = torch.optim.SGD(model.parameters(), lr = learn_rate, weight_decay=0.001)\n",
    "    else:\n",
    "        optimizer = torch.optim.Adadelta(model.parameters(), lr = learn_rate, weight_decay=0.001)\n",
    "\n",
    "    print(\"Activation:\",activation)\n",
    "\n",
    "    trainLostList, trainAccList, valLossList, valAccList  = train_model(model, K, trainset, testset, loss_fn, optimizer, num_epochs, \n",
    "                                                                        batch_size, validate_model = True, performance=accuracy, \n",
    "                                                                        device=\"cuda:0\", lr_scheduler=None)\n",
    "\n",
    "    plotValAccuracy(valAccList,num_epochs, activation, K)\n",
    "\n",
    "fig.savefig(str(K) + \"valAccuracy.png\")\n",
    "plt.show()\n",
    "dataset = MNISTParity(trainset, K, 128)\n",
    "dataset.plotRandomData()\n",
    "\n",
    "# just need to find good lr and weight_decay values for lazy methods to have more similar plots to paper\n"
   ],
   "outputs": [],
   "metadata": {}
  }
 ],
 "metadata": {
  "colab": {
   "name": "Sahibinden Veri Cekme Full.ipynb",
   "provenance": []
  },
  "interpreter": {
   "hash": "c73b42f4307b5621c20050e2a07bd2e616b471b51e8418e2c366c1833db7b122"
  },
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3.8.2 64-bit ('base': conda)"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.2"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {
    "height": "423.991px",
    "width": "239.29px"
   },
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}