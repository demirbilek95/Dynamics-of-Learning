{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import torchvision\n",
    "from torchvision.transforms import ToTensor, Normalize, Compose"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "from scripts.architecture import MLP\n",
    "from scripts.train import *\n",
    "from scripts.plot_utils import plot_loss_accuracy, plotValAccuracy"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "print(torch.__version__)\n",
    "print(np.__version__)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Create Parity Data Iterator"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "transforms = Compose([\n",
    "    ToTensor(),\n",
    "    Normalize((0.1307,), (0.3081,))\n",
    "])"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "# doesn't perform and transformation until we call the loader\n",
    "trainset = torchvision.datasets.MNIST(root='data', train=True, download=True, transform=transforms)\n",
    "testset = torchvision.datasets.MNIST(root='data', train=False, download=True, transform=transforms)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "learn_rate = 0.05\n",
    "num_epochs = 20\n",
    "batch_size = 128\n",
    "loss_fn = torch.nn.CrossEntropyLoss()"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "### For k = 1"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "k=1\n",
    "model = MLP(k, \"ReLU\")\n",
    "optimizer = torch.optim.Adadelta(model.parameters(), lr=learn_rate, weight_decay = 0.001)\n",
    "\n",
    "trainLostList, trainAccList, valLossList, valAccList  = train_model(model, k, trainset, testset, loss_fn, optimizer, num_epochs, batch_size, validate_model = True,\n",
    "                                                                     performance=accuracy, device=\"cuda:0\", lr_scheduler=None)\n"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "plot_loss_accuracy(trainLostList,valLossList,trainAccList,valAccList,num_epochs)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "k=1\n",
    "model2 = MLP(k, \"ReLU\")\n",
    "optimizer = torch.optim.SGD(model2.parameters(), lr=learn_rate)\n",
    "\n",
    "trainLostList, trainAccList, valLossList, valAccList  = train_model(model2, k, trainset, testset, loss_fn, optimizer, num_epochs, batch_size, validate_model = True,\n",
    "                                                                     performance=accuracy, device=\"cuda:0\",lr = learn_rate, lr_scheduler=None, updateWManually=True)\n"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "plot_loss_accuracy(trainLostList,valLossList,trainAccList,valAccList,num_epochs)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "### For k = 3"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "k = 3\n",
    "\n",
    "model3 = MLP(k,\"ReLU\")\n",
    "optimizer = torch.optim.Adadelta(model3.parameters(), lr=learn_rate, weight_decay = 0.001)\n",
    "\n",
    "trainLostList3, trainAccList3, valLossList3, valAccList3  = train_model(model3, k, trainset, testset, loss_fn, optimizer, num_epochs, batch_size, validate_model = True,\n",
    "                                                                     performance=accuracy, device=\"cuda:0\", lr_scheduler=None)\n"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "plot_loss_accuracy(trainLostList3,valLossList3,trainAccList3,valAccList3,num_epochs)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "k = 3\n",
    "model4 = MLP(k, \"ReLU\")\n",
    "optimizer = torch.optim.SGD(model4.parameters(), lr=learn_rate, weight_decay = 0.001)\n",
    "\n",
    "trainLostList4, trainAccList4, valLossList4, valAccList4  = train_model(model4, k, trainset, testset, loss_fn, optimizer, num_epochs, batch_size, validate_model = True,\n",
    "                                                                     performance=accuracy, device=\"cuda:0\", lr_scheduler=None)\n"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "plot_loss_accuracy(trainLostList4,valLossList4,trainAccList4,valAccList4,num_epochs)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "# Add Lazy methods\n",
    "learn_rate = 0.05\n",
    "K = 3\n",
    "num_epochs = 20\n",
    "\n",
    "fig = plt.figure()\n",
    "for activation in [\"ReLU\", \"NTK\", \"Gaussian features\", \"ReLU features\", \"linear features\", \"SGD\"]:\n",
    "    model = MLP(K, activation)\n",
    "\n",
    "    if \"features\" in activation:\n",
    "        # deactivate the first layer\n",
    "        optimizer = torch.optim.Adadelta(model.layer2.parameters(), lr = learn_rate, weight_decay=0.001)\n",
    "    elif \"NTK\" in activation:\n",
    "        paramsToUpdate = list(model.layer1.parameters()) + list(model.layer2.parameters())\n",
    "        optimizer = torch.optim.Adadelta(paramsToUpdate, lr = learn_rate, weight_decay=0.001)\n",
    "    elif \"SGD\" in activation:\n",
    "        optimizer = torch.optim.SGD(model.parameters(), lr = learn_rate, weight_decay=0.001)\n",
    "    else:\n",
    "        optimizer = torch.optim.Adadelta(model.parameters(), lr = learn_rate, weight_decay=0.001)\n",
    "\n",
    "    print(\"Activation:\",activation)\n",
    "\n",
    "    trainLostList, trainAccList, valLossList, valAccList  = train_model(model, K, trainset, testset, loss_fn, optimizer, num_epochs, \n",
    "                                                                        batch_size, validate_model = True, performance=accuracy, \n",
    "                                                                        device=\"cuda:0\", lr_scheduler=None)\n",
    "\n",
    "    plotValAccuracy(valAccList,num_epochs, activation, K)\n",
    "\n",
    "fig.savefig(str(K) + \"valAccuracy.png\")\n",
    "plt.show()\n",
    "dataset = MNISTParity(trainset, K, 128)\n",
    "dataset.plotRandomData()\n",
    "\n",
    "# just need to find good lr and weight_decay values for lazy methods to have more similar plots to paper\n"
   ],
   "outputs": [],
   "metadata": {}
  }
 ],
 "metadata": {
  "colab": {
   "name": "Sahibinden Veri Cekme Full.ipynb",
   "provenance": []
  },
  "interpreter": {
   "hash": "c73b42f4307b5621c20050e2a07bd2e616b471b51e8418e2c366c1833db7b122"
  },
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3.8.2 64-bit ('base': conda)"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.2"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {
    "height": "423.991px",
    "width": "239.29px"
   },
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}