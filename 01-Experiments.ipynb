{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import copy\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.ticker as mticker\n",
    "import torchvision\n",
    "from torchvision.transforms import ToTensor, Normalize, Compose"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scripts.architecture import MLP, MLPManual\n",
    "from scripts.train import *\n",
    "from scripts.plot_utils import plot_loss_accuracy, plotValAccuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(torch.__version__)\n",
    "print(np.__version__)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create Parity Data Iterator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "transforms = Compose([\n",
    "    ToTensor(),\n",
    "    Normalize((0.1307,), (0.3081,))\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# doesn't perform and transformation until we call the loader\n",
    "trainset = torchvision.datasets.MNIST(root='data', train=True, download=True, transform=transforms)\n",
    "testset = torchvision.datasets.MNIST(root='data', train=False, download=True, transform=transforms)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "learn_rate = 0.05\n",
    "num_epochs = 20\n",
    "batch_size = 128\n",
    "loss_type = \"Binary Cross Entropy\"\n",
    "loss_fn = torch.nn.BCELoss()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device('cuda:0' if torch.cuda.is_available() else 'cpu')\n",
    "print(device)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### For k = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "k=1\n",
    "model = MLP(k, \"ReLU\", loss_type)\n",
    "optimizer = torch.optim.Adadelta(model.parameters(), lr=learn_rate, weight_decay = 0.001)\n",
    "\n",
    "trainLostList_Ada1, trainAccList_Ada1, valLossList_Ada1, valAccList_Ada1  = train_model(model, k, trainset, testset, loss_type, loss_fn, optimizer, num_epochs, batch_size, validate_model = True, performance=accuracy, device=device, lr_scheduler=None, updateWManually=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_loss_accuracy(trainLostList_Ada1,valLossList_Ada1,trainAccList_Ada1,valAccList_Ada1,num_epochs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "k=1\n",
    "model2 = MLP(k, \"ReLU\", loss_type)\n",
    "optimizer = torch.optim.SGD(model2.parameters(), lr=learn_rate, weight_decay=0.001)\n",
    "\n",
    "trainLostList_sgd1, trainAccList_sgd1, valLossList_sgd1, valAccList_sgd1  = train_model(model2, k, trainset, testset, loss_type, loss_fn, optimizer, num_epochs, batch_size, validate_model = True, performance=accuracy, device=device,lr = learn_rate, lr_scheduler=None, updateWManually=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "plot_loss_accuracy(trainLostList_sgd1,valLossList_sgd1,trainAccList_sgd1,valAccList_sgd1,num_epochs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "k=1\n",
    "modelManual = MLPManual(k, learn_rate, loss_type, False)\n",
    "\n",
    "trainLostList_sgd1_scratch, trainAccList_sgd1_scratch, \\\n",
    "valLossList_sgd1_scratch, valAccList_sgd1_scratch  = train_model_manually(modelManual, k, trainset, testset,                                                                                                                                        loss_type, loss_fn, num_epochs, batch_size, validate_model = True,\n",
    "                                                                          device=device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(15,8))\n",
    "plt.ylim(0.5,1)\n",
    "plt.plot(valAccList_sgd1, label=\"SGD\")\n",
    "plt.plot(valAccList_Ada1, label=\"Adadelta\")\n",
    "plt.plot(valAccList_sgd1_scratch, label= \"SGD Scratch\")\n",
    "plt.gca().xaxis.set_major_locator(mticker.MultipleLocator(1))\n",
    "plt.legend();"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "### For k = 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "k = 3\n",
    "model3 = MLP(k,\"ReLU\", loss_type)\n",
    "optimizer = torch.optim.Adadelta(model3.parameters(), lr=learn_rate, weight_decay=0.001)\n",
    "\n",
    "trainLostList_Ada3, trainAccList_Ada3, \\\n",
    "valLossList_Ada3, valAccList_Ada3  = train_model(model3, k, trainset, testset, loss_type, loss_fn, optimizer, num_epochs, batch_size, validate_model = True, performance=accuracy, device=device, lr_scheduler=None)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_loss_accuracy(trainLostList_Ada3,valLossList_Ada3,trainAccList_Ada3,valAccList_Ada3,num_epochs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model4 = MLP(k, \"ReLU\", loss_type)\n",
    "optimizer = torch.optim.SGD(model4.parameters(), lr=learn_rate, weight_decay=0.001)\n",
    "\n",
    "trainLostList_sgd3, trainAccList_sgd3, valLossList_sgd3, valAccList_sgd3  = train_model(model4, k, trainset, testset, loss_type, loss_fn, optimizer, num_epochs, batch_size, validate_model = True, performance=accuracy, device=device, lr_scheduler=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_loss_accuracy(trainLostList_sgd3, valLossList_sgd3, trainAccList_sgd3, valAccList_sgd3, num_epochs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "k=3\n",
    "modelManual3 = MLPManual(k, learn_rate, loss_type, False)\n",
    "trainLostList_sgd3_scratch, trainAccList_sgd3_scratch, \\\n",
    "valLossList_sgd3_scratch, valAccList_sgd3_scratch  = train_model_manually(modelManual3, k, trainset, testset, loss_type, loss_fn, num_epochs,\n",
    "                                                                          batch_size, validate_model = True, device=device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(15,8))\n",
    "plt.ylim(0.4,1)\n",
    "plt.plot(valAccList_sgd3, label=\"SGD\")\n",
    "plt.plot(valAccList_Ada3, label=\"Adadelta\")\n",
    "plt.plot(valAccList_sgd3_scratch, label= \"SGD Scratch\")\n",
    "plt.gca().xaxis.set_major_locator(mticker.MultipleLocator(1))\n",
    "plt.legend();"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Try with the same weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "k = 3\n",
    "modelx = MLP(k, \"ReLU\", loss_type).to(device)\n",
    "\n",
    "w1 = copy.deepcopy(modelx.state_dict()[\"layer1.weight\"]).to(device)\n",
    "w2 = copy.deepcopy(modelx.state_dict()[\"layer2.weight\"]).to(device)\n",
    "\n",
    "optimizer = torch.optim.SGD(modelx.parameters(), lr=learn_rate)\n",
    "\n",
    "trainLostList_sgd3_w, trainAccList_sgd3_w, valLossList_sgd3_w, valAccList_sgd3_w  = train_model(modelx, k, trainset, testset, loss_type, loss_fn, optimizer, num_epochs, batch_size, validate_model = True, performance=accuracy, device=device, lr=learn_rate, lr_scheduler=None, updateWManually=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "modelManualx = MLPManual(k, learn_rate, loss_type, (w1.t(),w2.t()))\n",
    "trainLostList_sgd3_scratch_w, trainAccList_sgd3_scratch_w, \\\n",
    "valLossList_sgd3_scratch_w, valAccList_sgd3_scratch_w  = train_model_manually(modelManualx, k, trainset, testset, loss_type, loss_fn, num_epochs,\n",
    "                                                                          batch_size, validate_model = True, device=device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "plt.figure(figsize=(15,8))\n",
    "plt.plot(range(1,21),valAccList_sgd3_w, color = \"blue\", label = \"BP SGD Pytorch\")\n",
    "plt.plot(range(1,21),valAccList_sgd3_scratch_w, color = \"green\", label = \"BP SGD Dogan\")\n",
    "\n",
    "plt.ylim(0.4,1.05)\n",
    "plt.title(\"Test Accuracy k=3\")\n",
    "plt.xlabel(\"Iteration\")\n",
    "plt.ylabel(\"Accuracy\")\n",
    "plt.gca().xaxis.set_major_locator(mticker.MultipleLocator(1))\n",
    "plt.legend()\n",
    "plt.grid(True)\n",
    "\n",
    "plt.savefig(\"plots/doganVSPytorch.png\")\n",
    "\n",
    "plt.show();\n",
    "\n",
    "# They are gonna be different, because I recreate the data every epoch\n",
    "# Even without recreating, results are different?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = torch.randn(2,3)\n",
    "x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# Add Lazy methods\n",
    "learn_rate = 0.05\n",
    "K = 3\n",
    "num_epochs = 20\n",
    "loss_type = \"Binary Cross Entropy\"\n",
    "\n",
    "fig = plt.figure(figsize=(15,9))\n",
    "for activation in [\"ReLU\", \"NTK\", \"Gaussian features\", \"ReLU features\", \"Linear features\", \"SGD\", \"SGD Dogan\"]:\n",
    "    if activation != \"SGD_Scratch\":\n",
    "        model = MLP(K, activation, loss_type)\n",
    "        if \"features\" in activation:\n",
    "            # deactivate the first layer\n",
    "            optimizer = torch.optim.Adadelta(model.layer2.parameters(), lr = learn_rate, weight_decay=0.001)\n",
    "        elif \"NTK\" in activation:\n",
    "            paramsToUpdate = list(model.layer1.parameters()) + list(model.layer2.parameters())\n",
    "            optimizer = torch.optim.Adadelta(paramsToUpdate, lr = learn_rate, weight_decay=0.001)\n",
    "        elif \"SGD\" in activation:\n",
    "            optimizer = torch.optim.SGD(model.parameters(), lr = learn_rate, weight_decay=0.001)\n",
    "        else:\n",
    "            optimizer = torch.optim.Adadelta(model.parameters(), lr = learn_rate, weight_decay=0.001)\n",
    "\n",
    "        print(\"Activation:\",activation)\n",
    "\n",
    "        trainLostList, trainAccList, valLossList, valAccList  = train_model(model, K, trainset, testset, loss_type, loss_fn, optimizer, num_epochs,\n",
    "                                                                            batch_size, validate_model = True, performance=accuracy,\n",
    "                                                                            device=\"cuda:0\", lr_scheduler=None)\n",
    "    else:\n",
    "        print(\"Activation:\",activation)\n",
    "        modelManual3 = MLPManual(K, learn_rate, loss_type, False)\n",
    "\n",
    "        trainLostList, trainAccList, valLossList, valAccList  = train_model_manually(modelManual3, K, trainset, testset, loss_type, loss_fn, num_epochs,\n",
    "                                                                                  batch_size, validate_model = True, device=device)\n",
    "\n",
    "    plotValAccuracy(valAccList, num_epochs, activation, K)\n",
    "\n",
    "fig.savefig(\"plots/\" + str(K) + \"valAccuracy.png\")\n",
    "plt.show()\n",
    "dataset = MNISTParity(trainset, K, 128)\n",
    "dataset.plotRandomData()\n",
    "\n",
    "# just need to find good lr and weight_decay values for lazy methods to have more similar plots to paper"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "name": "Sahibinden Veri Cekme Full.ipynb",
   "provenance": []
  },
  "interpreter": {
   "hash": "c684a6fc7ea5d844d0888e3fc402a914f9a0757a714c6fe2ccce21fe8443d9ca"
  },
  "kernelspec": {
   "display_name": "Python 3.8.2 64-bit ('base': conda)",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.2"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {
    "height": "423.991px",
    "width": "239.29px"
   },
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
